---
title: "Introduction to methods in environmental epidemiology"
subtitle: "Day 1 lab 3: Likelihood-based models in environmental epidemiology"
author: "Robbie M. Parks"
date: today
format: html
editor: visual
---


::: {.cell}
## 0: Preparation

Load necessary packages

```{r}
library(here)
library(dplyr)
library(ggplot2)
library(MASS)
library(survival)
library(Epi)
library(ResourceSelection)
library(datasets)  # for airquality
```
:::

::: {.cell}
## 0: Declare Folder Paths
```{r}
ProjectFolder <- here("data")
```
:::

## Introduction

This lab demonstrates how to fit various likelihood-based regression models in the context of environmental epidemiology using real data (`airquality`) and simulated health outcomes.

## Use Real-World Data: `airquality` with Simulated Mortality

```{r real-health-data}
data <- airquality %>%
  filter(!is.na(Ozone), !is.na(Temp)) %>%
  mutate(
    mortality = rpois(n(), lambda = exp(0.01 * Temp + 0.005 * Ozone)),
    high_mort = as.integer(mortality > quantile(mortality, 0.75)),
    day_of_week = sample(c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"), n(), replace = TRUE),
    total_deaths = mortality + rbinom(n(), size = 10, prob = 0.5),
    deaths_over5 = rbinom(n(), size = total_deaths, prob = 0.6)
  )
```

## 1. Linear Regression (Normal Likelihood)

```{r real-normal-model}
model_normal <- lm(mortality ~ Temp + Ozone, data = data)
summary(model_normal)
```

```{r normal-goodness-of-fit}
par(mfrow = c(1, 2))
plot(model_normal$fitted.values, resid(model_normal),
     main = "Residuals vs Fitted",
     xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, lty = 2)
hist(resid(model_normal), main = "Histogram of Residuals", xlab = "Residuals")
```

If residuals are roughly centered around zero and evenly spread (no funnel shape), and the histogram appears approximately normal, then the linear model fits reasonably well.

### Plot

```{r real-normal-plot}
ggplot(data, aes(x = Temp, y = mortality)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Simulated Mortality vs Temperature")
```

## 2. Poisson Regression (Count Data)

```{r real-poisson-model}
model_poisson <- glm(mortality ~ Temp + Ozone + day_of_week, 
                     family = poisson(), 
                     data = data)
summary(model_poisson)
```

```{r poisson-goodness-of-fit}
p_value <- 1 - pchisq(model_poisson$deviance, df = model_poisson$df.residual)
cat("Deviance GOF Test p-value:", round(p_value, 4))
```

If the p-value is greater than 0.05, it suggests that the model fits the data well. If it is less than 0.05, the model may not fit well.

### Plot

```{r real-poisson-plot}
data$pred_mortality <- predict(model_poisson, type = "response")
ggplot(data, aes(x = pred_mortality, y = mortality)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(title = "Predicted vs Observed Mortality (Poisson Model)")
```

## 3. Logistic Regression (Bernoulli Likelihood)

```{r real-logistic-model}
model_logistic <- glm(high_mort ~ Temp + Ozone, 
                      family = binomial(), 
                      data = data)
summary(model_logistic)
```

```{r logistic-goodness-of-fit}
library(ResourceSelection)
hoslem_test <- hoslem.test(model_logistic$y, fitted(model_logistic), g = 10)
cat("Hosmer-Lemeshow Test p-value:", round(hoslem_test$p.value, 4))
```

If the Hosmer-Lemeshow test p-value is > 0.05, this suggests no significant difference between predicted and observed values, indicating good fit. A low p-value implies poor fit.

### Plot

```{r real-logistic-plot}
ggplot(data, aes(x = fitted(model_logistic), fill = as.factor(high_mort))) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs(title = "Fitted Probabilities for High Mortality Days", fill = "High Mortality")
```

## 4. Binomial Regression (Grouped Binary Outcomes)

```{r real-binomial-model}
model_binomial <- glm(cbind(deaths_over5, total_deaths - deaths_over5) ~ Temp + Ozone, 
                      family = binomial(), 
                      data = data)
summary(model_binomial)
```

```{r binomial-goodness-of-fit}
p_value_binomial <- 1 - pchisq(model_binomial$deviance, df = model_binomial$df.residual)
cat("Binomial Deviance GOF Test p-value:", round(p_value_binomial, 4))
```

If the p-value is greater than 0.05, it suggests that the model fits the data well. If it is less than 0.05, the model may not fit well.

### Plot

```{r real-binomial-plot}
data$pred_prob_over5 <- predict(model_binomial, type = "response")
ggplot(data, aes(x = pred_prob_over5)) +
  geom_histogram(bins = 30, fill = "skyblue", alpha = 0.7) +
  labs(title = "Predicted Proportion of Deaths Over Age 5")
```

---

This Quarto document covers the basics of various potential likelihood models with common data types and research questions. You can explore further with datasets like `airquality`, or public mortality databases from CDC Wonder or Eurostat.
